{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo:normalize, take in regard pid, as of now i assume that the order is the same in features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeaturespath = 'task2_k49am2lqi/train_features.csv'\n",
    "testfeaturespath = 'task2_k49am2lqi/test_features.csv'\n",
    "tlabelspath = 'task2_k49am2lqi/train_labels.csv'\n",
    "tfeatures = pd.read_csv(tfeaturespath)\n",
    "testfeatures = pd.read_csv(testfeaturespath)\n",
    "tlabels = pd.read_csv(tlabelspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feature construction\n",
    "raw = np.zeros((tfeatures.shape[0]//12, (tfeatures.loc[1].size-2)*3-2))\n",
    "for i in tqdm(range(raw.shape[0])):\n",
    "    raw[i] = tfeatures[12*i:12*(i+1)].describe().loc[['mean', 'min', 'max']].unstack().drop(['pid', 'Time', ('Age','min'), ('Age', 'max')])\n",
    "np.save('task2_k49am2lqi/raw_with_nan', raw)\n",
    "#impute nans\n",
    "mean = np.nanmean(raw, axis = 0)\n",
    "inds = np.where(np.isnan(raw))\n",
    "raw[inds] = np.take(mean, inds[1])\n",
    "np.save('task2_k49am2lqi/raw', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feature construction testset\n",
    "testraw = np.zeros((testfeatures.shape[0]//12, (testfeatures.loc[1].size-2)*3-2))\n",
    "for i in tqdm(range(testraw.shape[0])):\n",
    "    testraw[i] = testfeatures[12*i:12*(i+1)].describe().loc[['mean', 'min', 'max']].unstack().drop(['pid', 'Time', ('Age','min'), ('Age', 'max')])\n",
    "np.save('task2_k49am2lqi/testraw_with_nan', testraw)\n",
    "#impute nans\n",
    "mean = np.nanmean(testraw, axis = 0)\n",
    "inds = np.where(np.isnan(testraw))\n",
    "testraw[inds] = np.take(mean, inds[1])\n",
    "np.save('task2_k49am2lqi/testraw', testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'task2_k49am2lqi/raw.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9eaf373b2bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task2_k49am2lqi/raw.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'task2_k49am2lqi/raw.npy'"
     ]
    }
   ],
   "source": [
    "raw = np.load('task2_k49am2lqi/raw.npy')\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(raw)\n",
    "raw = scaler.transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels1 = tlabels[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']].values\n",
    "tlabels2 = tlabels['LABEL_Sepsis'].values\n",
    "tlabels3 = tlabels[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(raw, tlabels1, test_size=0.2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(raw, tlabels2, test_size=0.2)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(raw, tlabels3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train33 = [y_train3[:,0], y_train3[:,1], y_train3[:,2], y_train3[:,3]]\n",
    "y_test33 = [y_test3[:,0], y_test3[:,1], y_test3[:,2], y_test3[:,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(raw[0].size,)),\n",
    "        layers.Dense(50, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(30, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(25, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(tlabels1.shape[1], activation='sigmoid', name=\"layer5\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(raw[0].size,)),\n",
    "        layers.Dense(50, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(30, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(25, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(1, activation='sigmoid', name=\"layer5\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "input3 = keras.Input(shape=(raw[0].size,))\n",
    "x1 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x2 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x3 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x4 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "        \n",
    "y1 = layers.Dense(30, activation=\"relu\")(x1)\n",
    "y2 = layers.Dense(30, activation=\"relu\")(x2)\n",
    "y3 = layers.Dense(30, activation=\"relu\")(x3)\n",
    "y4 = layers.Dense(30, activation=\"relu\")(x4)\n",
    "\n",
    "z1 = layers.Dense(10, activation=\"relu\")(y1)\n",
    "z2 = layers.Dense(10, activation=\"relu\")(y2)\n",
    "z3 = layers.Dense(10, activation=\"relu\")(y3)\n",
    "z4 = layers.Dense(10, activation=\"relu\")(y4)\n",
    "\n",
    "out1 = layers.Dense(1, activation=\"linear\")(y1)\n",
    "out2 = layers.Dense(1, activation=\"linear\")(y2)\n",
    "out3 = layers.Dense(1, activation=\"linear\")(y3)\n",
    "out4 = layers.Dense(1, activation=\"linear\")(y4)\n",
    "\n",
    "model3 = keras.Model(inputs=input3, outputs=[out1,out2,out3,out4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=tf.keras.losses.MeanSquaredError(),optimizer='adam',metrics=[tf.keras.metrics.AUC(curve = 'ROC')])\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.AUC(curve = 'ROC')])\n",
    "model3.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam',metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(\n",
    "    X_train1,\n",
    "    y_train1,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test1, y_test1),\n",
    ")\n",
    "model1.save('task2_k49am2lqi/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(\n",
    "    X_train2,\n",
    "    y_train2,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test2, y_test2),\n",
    ")\n",
    "model2.save('task2_k49am2lqi/model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model3.fit(\n",
    "    X_train3,\n",
    "    y_train33,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test3, y_test33),\n",
    ")\n",
    "model3.save('task2_k49am2lqi/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testraw = np.load('task2_k49am2lqi/testraw.npy')\n",
    "testraw = scaler.transform(testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model1.predict(testraw)\n",
    "result2 = model2.predict(testraw)\n",
    "result3 = model3.predict(testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming = ['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "upload = np.zeros((testraw.shape[0], len(naming)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = testfeatures['pid'].values\n",
    "PID = np.empty(testraw.shape[0])\n",
    "for i in range(PID.size):\n",
    "    PID[i] = pid[12*i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload[:,0] = PID\n",
    "upload[:,1:11] = result1\n",
    "upload[:,11] = result2.ravel()\n",
    "upload[:,12] = result3[0].ravel()\n",
    "upload[:,13] = result3[1].ravel()\n",
    "upload[:,14] = result3[2].ravel()\n",
    "upload[:,15] = result3[3].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(data=upload, columns = naming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prediction4.zip', index=False, float_format='%.3f', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
