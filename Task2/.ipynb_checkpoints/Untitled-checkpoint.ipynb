{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo:normalize, take in regard pid, as of now i assume that the order is the same in features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import layers\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfeaturespath = '/Users/jg/NonCloudData/IML/task2_k49am2lqi/train_features.csv'\n",
    "testfeaturespath = '/Users/jg/NonCloudData/IML/task2_k49am2lqi/test_features.csv'\n",
    "tlabelspath = '/Users/jg/NonCloudData/IML/task2_k49am2lqi/train_labels.csv'\n",
    "tfeatures = pd.read_csv(tfeaturespath)\n",
    "testfeatures = pd.read_csv(testfeaturespath)\n",
    "tlabels = pd.read_csv(tlabelspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feature construction\n",
    "raw = np.zeros((tfeatures.shape[0]//12, (tfeatures.loc[1].size-2)*3-2))\n",
    "for i in tqdm(range(raw.shape[0])):\n",
    "    raw[i] = tfeatures[12*i:12*(i+1)].describe().loc[['mean', 'min', 'max']].unstack().drop(['pid', 'Time', ('Age','min'), ('Age', 'max')])\n",
    "np.save('task2_k49am2lqi/raw_with_nan', raw)\n",
    "#impute nans\n",
    "mean = np.nanmean(raw, axis = 0)\n",
    "inds = np.where(np.isnan(raw))\n",
    "raw[inds] = np.take(mean, inds[1])\n",
    "np.save('task2_k49am2lqi/raw', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#feature construction testset\n",
    "testraw = np.zeros((testfeatures.shape[0]//12, (testfeatures.loc[1].size-2)*3-2))\n",
    "for i in tqdm(range(testraw.shape[0])):\n",
    "    testraw[i] = testfeatures[12*i:12*(i+1)].describe().loc[['mean', 'min', 'max']].unstack().drop(['pid', 'Time', ('Age','min'), ('Age', 'max')])\n",
    "np.save('task2_k49am2lqi/testraw_with_nan', testraw)\n",
    "#impute nans\n",
    "mean = np.nanmean(testraw, axis = 0)\n",
    "inds = np.where(np.isnan(testraw))\n",
    "testraw[inds] = np.take(mean, inds[1])\n",
    "np.save('task2_k49am2lqi/testraw', testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np.load('task2_k49am2lqi/raw.npy')\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(raw)\n",
    "raw = scaler.transform(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlabels1 = tlabels[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']].values\n",
    "tlabels2 = tlabels['LABEL_Sepsis'].values\n",
    "tlabels3 = tlabels[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(raw, tlabels1, test_size=0.2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(raw, tlabels2, test_size=0.2)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(raw, tlabels3, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train33 = [y_train3[:,0], y_train3[:,1], y_train3[:,2], y_train3[:,3]]\n",
    "y_test33 = [y_test3[:,0], y_test3[:,1], y_test3[:,2], y_test3[:,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(raw[0].size,)),\n",
    "        layers.Dense(50, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(30, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(25, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(tlabels1.shape[1], activation='sigmoid', name=\"layer5\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(raw[0].size,)),\n",
    "        layers.Dense(50, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(30, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(25, activation=\"relu\", name=\"layer4\"),\n",
    "        layers.Dense(1, activation='sigmoid', name=\"layer5\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "input3 = keras.Input(shape=(raw[0].size,))\n",
    "x1 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x2 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x3 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "x4 = layers.Dense(50, activation=\"relu\")(input3)\n",
    "        \n",
    "y1 = layers.Dense(30, activation=\"relu\")(x1)\n",
    "y2 = layers.Dense(30, activation=\"relu\")(x2)\n",
    "y3 = layers.Dense(30, activation=\"relu\")(x3)\n",
    "y4 = layers.Dense(30, activation=\"relu\")(x4)\n",
    "\n",
    "z1 = layers.Dense(10, activation=\"relu\")(y1)\n",
    "z2 = layers.Dense(10, activation=\"relu\")(y2)\n",
    "z3 = layers.Dense(10, activation=\"relu\")(y3)\n",
    "z4 = layers.Dense(10, activation=\"relu\")(y4)\n",
    "\n",
    "out1 = layers.Dense(1, activation=\"linear\")(y1)\n",
    "out2 = layers.Dense(1, activation=\"linear\")(y2)\n",
    "out3 = layers.Dense(1, activation=\"linear\")(y3)\n",
    "out4 = layers.Dense(1, activation=\"linear\")(y4)\n",
    "\n",
    "model3 = keras.Model(inputs=input3, outputs=[out1,out2,out3,out4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=tf.keras.losses.MeanSquaredError(),optimizer='adam',metrics=[tf.keras.metrics.AUC(curve = 'ROC')])\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.AUC(curve = 'ROC')])\n",
    "model3.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam',metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15196 samples, validate on 3799 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    X_train1,\n",
    "    y_train1,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test1, y_test1),\n",
    ")\n",
    "model1.save('task2_k49am2lqi/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15196 samples, validate on 3799 samples\n",
      "Epoch 1/5\n",
      "15196/15196 [==============================] - 3s 198us/sample - loss: 0.2929 - auc_11: 0.4818 - val_loss: 0.2326 - val_auc_11: 0.5164\n",
      "Epoch 2/5\n",
      "15196/15196 [==============================] - 1s 83us/sample - loss: 0.2223 - auc_11: 0.6027 - val_loss: 0.2176 - val_auc_11: 0.6277\n",
      "Epoch 3/5\n",
      "15196/15196 [==============================] - 1s 83us/sample - loss: 0.2079 - auc_11: 0.6867 - val_loss: 0.2104 - val_auc_11: 0.6664\n",
      "Epoch 4/5\n",
      "15196/15196 [==============================] - 1s 87us/sample - loss: 0.1983 - auc_11: 0.7384 - val_loss: 0.2128 - val_auc_11: 0.6626\n",
      "Epoch 5/5\n",
      "15196/15196 [==============================] - 1s 87us/sample - loss: 0.1921 - auc_11: 0.7672 - val_loss: 0.2102 - val_auc_11: 0.6887\n",
      "INFO:tensorflow:Assets written to: task2_k49am2lqi/model2/assets\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(\n",
    "    X_train2,\n",
    "    y_train2,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test2, y_test2),\n",
    ")\n",
    "model2.save('task2_k49am2lqi/model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15196 samples, validate on 3799 samples\n",
      "Epoch 1/5\n",
      "15196/15196 [==============================] - 5s 322us/sample - loss: 11315.9192 - dense_77_loss: 88.0631 - dense_78_loss: 3187.4836 - dense_79_loss: 4777.3164 - dense_80_loss: 3241.2214 - dense_77_coeff_determination: -6.3691 - dense_78_coeff_determination: -20.4237 - dense_79_coeff_determination: -1379.8354 - dense_80_coeff_determination: -14.5433 - val_loss: 2736.5768 - val_dense_77_loss: 32.1803 - val_dense_78_loss: 798.0167 - val_dense_79_loss: 1090.4513 - val_dense_80_loss: 801.4180 - val_dense_77_coeff_determination: -1.7548 - val_dense_78_coeff_determination: -4.0059 - val_dense_79_coeff_determination: -335.9601 - val_dense_80_coeff_determination: -3.0688\n",
      "Epoch 2/5\n",
      "15196/15196 [==============================] - 2s 100us/sample - loss: 2046.1523 - dense_77_loss: 26.3214 - dense_78_loss: 599.9713 - dense_79_loss: 788.8972 - dense_80_loss: 628.9792 - dense_77_coeff_determination: -1.3140 - dense_78_coeff_determination: -2.9362 - dense_79_coeff_determination: -231.3353 - dense_80_coeff_determination: -1.9760 - val_loss: 1745.7939 - val_dense_77_loss: 21.9138 - val_dense_78_loss: 525.0797 - val_dense_79_loss: 660.3450 - val_dense_80_loss: 528.3532 - val_dense_77_coeff_determination: -0.8605 - val_dense_78_coeff_determination: -2.2954 - val_dense_79_coeff_determination: -204.3205 - val_dense_80_coeff_determination: -1.6896\n",
      "Epoch 3/5\n",
      "15196/15196 [==============================] - 2s 102us/sample - loss: 1405.8160 - dense_77_loss: 18.5599 - dense_78_loss: 417.0299 - dense_79_loss: 527.9449 - dense_80_loss: 441.9549 - dense_77_coeff_determination: -0.6022 - dense_78_coeff_determination: -1.7011 - dense_79_coeff_determination: -151.6618 - dense_80_coeff_determination: -1.1042 - val_loss: 1261.5894 - val_dense_77_loss: 15.9583 - val_dense_78_loss: 380.1746 - val_dense_79_loss: 472.8692 - val_dense_80_loss: 386.1274 - val_dense_77_coeff_determination: -0.3496 - val_dense_78_coeff_determination: -1.3873 - val_dense_79_coeff_determination: -144.7724 - val_dense_80_coeff_determination: -0.9576\n",
      "Epoch 4/5\n",
      "15196/15196 [==============================] - 2s 107us/sample - loss: 1010.1375 - dense_77_loss: 13.6985 - dense_78_loss: 299.3885 - dense_79_loss: 371.2182 - dense_80_loss: 324.8284 - dense_77_coeff_determination: -0.1908 - dense_78_coeff_determination: -0.9314 - dense_79_coeff_determination: -105.9768 - dense_80_coeff_determination: -0.5403 - val_loss: 910.3124 - val_dense_77_loss: 12.0438 - val_dense_78_loss: 273.2716 - val_dense_79_loss: 331.5062 - val_dense_80_loss: 288.5089 - val_dense_77_coeff_determination: -0.0132 - val_dense_78_coeff_determination: -0.7148 - val_dense_79_coeff_determination: -100.5593 - val_dense_80_coeff_determination: -0.4621\n",
      "Epoch 5/5\n",
      "15196/15196 [==============================] - 2s 101us/sample - loss: 721.1518 - dense_77_loss: 10.8132 - dense_78_loss: 214.1508 - dense_79_loss: 252.6328 - dense_80_loss: 243.1883 - dense_77_coeff_determination: 0.0719 - dense_78_coeff_determination: -0.3960 - dense_79_coeff_determination: -71.7645 - dense_80_coeff_determination: -0.1608 - val_loss: 653.5647 - val_dense_77_loss: 10.3884 - val_dense_78_loss: 198.2338 - val_dense_79_loss: 222.3628 - val_dense_80_loss: 219.2202 - val_dense_77_coeff_determination: 0.1336 - val_dense_78_coeff_determination: -0.2454 - val_dense_79_coeff_determination: -66.6288 - val_dense_80_coeff_determination: -0.1109\n",
      "INFO:tensorflow:Assets written to: task2_k49am2lqi/model3/assets\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(\n",
    "    X_train3,\n",
    "    y_train33,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test3, y_test33),\n",
    ")\n",
    "model3.save('task2_k49am2lqi/model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "testraw = np.load('task2_k49am2lqi/testraw.npy')\n",
    "testraw = scaler.transform(testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = model1.predict(testraw)\n",
    "result2 = model2.predict(testraw)\n",
    "result3 = model3.predict(testraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming = ['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2','LABEL_Sepsis','LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "upload = np.zeros((testraw.shape[0], len(naming)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = testfeatures['pid'].values\n",
    "PID = np.empty(testraw.shape[0])\n",
    "for i in range(PID.size):\n",
    "    PID[i] = pid[12*i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload[:,0] = PID\n",
    "upload[:,1:11] = result1\n",
    "upload[:,11] = result2.ravel()\n",
    "upload[:,12] = result3[0].ravel()\n",
    "upload[:,13] = result3[1].ravel()\n",
    "upload[:,14] = result3[2].ravel()\n",
    "upload[:,15] = result3[3].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.DataFrame(data=upload, columns = naming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prediction4.zip', index=False, float_format='%.3f', compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
